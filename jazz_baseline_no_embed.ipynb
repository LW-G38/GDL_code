{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compose: Training a model to generate music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy\n",
    "import pydot\n",
    "from matplotlib import pyplot\n",
    "from music21 import note, chord\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.utils import plot_model\n",
    "from keras import regularizers\n",
    "\n",
    "from models.RNNAttention import get_distinct, create_lookups, prepare_sequences, get_music_list, create_network_no_embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run params\n",
    "section = 'compose'\n",
    "run_id = 'no_embed'\n",
    "genre_name = 'jazz'\n",
    "composer_name='JohnColtrane'\n",
    "\n",
    "run_folder = 'run/{}/{}/'.format(section, genre_name)\n",
    "run_folder += '_'.join([run_id, composer_name])\n",
    "\n",
    "\n",
    "store_folder = os.path.join(run_folder, 'store')\n",
    "data_folder = os.path.join('data', genre_name, composer_name)\n",
    "\n",
    "if not os.path.exists(run_folder):\n",
    "    os.mkdir(run_folder)\n",
    "    os.mkdir(os.path.join(run_folder, 'store'))\n",
    "    os.mkdir(os.path.join(run_folder, 'output'))\n",
    "    os.mkdir(os.path.join(run_folder, 'weights'))\n",
    "    os.mkdir(os.path.join(run_folder, 'viz'))\n",
    "    \n",
    "\n",
    "\n",
    "mode = 'load' # 'load' # \n",
    "\n",
    "# data params\n",
    "intervals = range(1)\n",
    "seq_len = 32\n",
    "\n",
    "# model params\n",
    "#embed_size = 1\n",
    "rnn_units = 256\n",
    "use_attention = True\n",
    "reg = None\n",
    "#reg = regularizers.l2(0.01)\n",
    "#reg = regularizers.l1_l2(l1=0.1,l2=0.1)\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/jazz/JohnColtrane'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 'build':\n",
    "    \n",
    "    music_list, parser = get_music_list(data_folder)\n",
    "    print(len(music_list), 'files in total')\n",
    "\n",
    "    notes = []\n",
    "    durations = []\n",
    "\n",
    "    for i, file in enumerate(music_list):\n",
    "        print(i+1, \"Parsing %s\" % file)\n",
    "        original_score = parser.parse(file).chordify()\n",
    "        \n",
    "\n",
    "        for interval in intervals:\n",
    "\n",
    "            score = original_score.transpose(interval)\n",
    "\n",
    "            notes.extend(['START'] * seq_len)\n",
    "            durations.extend([0]* seq_len)\n",
    "            #notes.extend(['START'])\n",
    "            #durations.extend([0])\n",
    "\n",
    "            for element in score.flat:\n",
    "                \n",
    "                if isinstance(element, note.Note):\n",
    "                    if element.isRest:\n",
    "                        notes.append(str(element.name))\n",
    "                        durations.append(element.duration.quarterLength)\n",
    "                    else:\n",
    "                        notes.append(str(element.nameWithOctave))\n",
    "\n",
    "                if isinstance(element, chord.Chord):\n",
    "                    notes.append('.'.join(n.nameWithOctave for n in element.pitches))\n",
    "                    durations.append(element.duration.quarterLength)\n",
    "\n",
    "    with open(os.path.join(store_folder, 'notes'), 'wb') as f:\n",
    "        pickle.dump(notes, f) #['G2', 'D3', 'B3', 'A3', 'B3', 'D3', 'B3', 'D3', 'G2',...]\n",
    "    with open(os.path.join(store_folder, 'durations'), 'wb') as f:\n",
    "        pickle.dump(durations, f)\n",
    "else:\n",
    "    with open(os.path.join(store_folder, 'notes'), 'rb') as f:\n",
    "        notes = pickle.load(f) #['G2', 'D3', 'B3', 'A3', 'B3', 'D3', 'B3', 'D3', 'G2',...]\n",
    "    with open(os.path.join(store_folder, 'durations'), 'rb') as f:\n",
    "        durations = pickle.load(f) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the lookup tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the distinct sets of notes and durations\n",
    "note_names, n_notes = get_distinct(notes)\n",
    "duration_names, n_durations = get_distinct(durations)\n",
    "#velocity_names, n_velocities = get_distinct(velocities)\n",
    "distincts = [note_names, n_notes, duration_names, n_durations]\n",
    "\n",
    "with open(os.path.join(store_folder, 'distincts'), 'wb') as f:\n",
    "    pickle.dump(distincts, f)\n",
    "\n",
    "# make the lookup dictionaries for notes and dictionaries and save\n",
    "note_to_int, int_to_note = create_lookups(note_names)\n",
    "duration_to_int, int_to_duration = create_lookups(duration_names)\n",
    "#velocity_to_int, int_to_velocity = create_lookups(velocity_names)\n",
    "lookups = [note_to_int, int_to_note, duration_to_int, int_to_duration]\n",
    "\n",
    "with open(os.path.join(store_folder, 'lookups'), 'wb') as f:\n",
    "    pickle.dump(lookups, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "note_to_int\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'A2': 0,\n",
       " 'A2.B2': 1,\n",
       " 'A2.F#3': 2,\n",
       " 'A2.F3': 3,\n",
       " 'A3': 4,\n",
       " 'A3.B-3': 5,\n",
       " 'A3.B3': 6,\n",
       " 'A3.C#4': 7,\n",
       " 'A3.C4': 8,\n",
       " 'A3.D4': 9,\n",
       " 'A3.E-4': 10,\n",
       " 'A3.F4': 11,\n",
       " 'A3.G4': 12,\n",
       " 'A4': 13,\n",
       " 'A4.B-4': 14,\n",
       " 'A4.B-4.B4': 15,\n",
       " 'A4.B-4.C5': 16,\n",
       " 'A4.B4': 17,\n",
       " 'A4.B4.C#5': 18,\n",
       " 'A4.C#5': 19,\n",
       " 'A4.C5': 20,\n",
       " 'A4.D5': 21,\n",
       " 'A4.E-5': 22,\n",
       " 'A5': 23,\n",
       " 'A5.B-5': 24,\n",
       " 'A5.B5': 25,\n",
       " 'A5.C6': 26,\n",
       " 'B-2': 27,\n",
       " 'B-2.B2': 28,\n",
       " 'B-2.C3': 29,\n",
       " 'B-2.D3': 30,\n",
       " 'B-2.F#3': 31,\n",
       " 'B-2.F#4': 32,\n",
       " 'B-2.F3': 33,\n",
       " 'B-3': 34,\n",
       " 'B-3.B3': 35,\n",
       " 'B-3.C#4': 36,\n",
       " 'B-3.C4': 37,\n",
       " 'B-3.D4': 38,\n",
       " 'B-3.E-4': 39,\n",
       " 'B-3.F#4': 40,\n",
       " 'B-3.F#4.G4': 41,\n",
       " 'B-3.F4': 42,\n",
       " 'B-3.G#4': 43,\n",
       " 'B-3.G4': 44,\n",
       " 'B-4': 45,\n",
       " 'B-4.B4': 46,\n",
       " 'B-4.C#5': 47,\n",
       " 'B-4.C5': 48,\n",
       " 'B-4.D5': 49,\n",
       " 'B-4.E-5': 50,\n",
       " 'B-5': 51,\n",
       " 'B-5.B5': 52,\n",
       " 'B2': 53,\n",
       " 'B2.B3': 54,\n",
       " 'B2.C#3': 55,\n",
       " 'B2.C#5': 56,\n",
       " 'B2.C3': 57,\n",
       " 'B2.C5': 58,\n",
       " 'B2.D3': 59,\n",
       " 'B2.F3': 60,\n",
       " 'B2.G3': 61,\n",
       " 'B3': 62,\n",
       " 'B3.A4': 63,\n",
       " 'B3.C#4': 64,\n",
       " 'B3.C4': 65,\n",
       " 'B3.C5': 66,\n",
       " 'B3.D4': 67,\n",
       " 'B3.E-4': 68,\n",
       " 'B3.E4': 69,\n",
       " 'B3.F4': 70,\n",
       " 'B3.G4': 71,\n",
       " 'B4': 72,\n",
       " 'B4.A5': 73,\n",
       " 'B4.C#5': 74,\n",
       " 'B4.C5': 75,\n",
       " 'B4.D5': 76,\n",
       " 'B4.E-5': 77,\n",
       " 'B4.E5': 78,\n",
       " 'B5': 79,\n",
       " 'B5.C#6': 80,\n",
       " 'B5.C6': 81,\n",
       " 'B5.D6': 82,\n",
       " 'B5.E-6': 83,\n",
       " 'C#3': 84,\n",
       " 'C#3.D3': 85,\n",
       " 'C#3.D4': 86,\n",
       " 'C#3.E-3': 87,\n",
       " 'C#4': 88,\n",
       " 'C#4.C#5': 89,\n",
       " 'C#4.D4': 90,\n",
       " 'C#4.D4.E-4': 91,\n",
       " 'C#4.E-4': 92,\n",
       " 'C#4.E-4.E4': 93,\n",
       " 'C#4.E4': 94,\n",
       " 'C#4.E4.F#4': 95,\n",
       " 'C#4.F#4': 96,\n",
       " 'C#4.F4': 97,\n",
       " 'C#4.G#4': 98,\n",
       " 'C#4.G4': 99,\n",
       " 'C#5': 100,\n",
       " 'C#5.B5': 101,\n",
       " 'C#5.D5': 102,\n",
       " 'C#5.E-5': 103,\n",
       " 'C#5.E5': 104,\n",
       " 'C#6': 105,\n",
       " 'C#6.D6': 106,\n",
       " 'C3': 107,\n",
       " 'C3.C#3': 108,\n",
       " 'C3.D3': 109,\n",
       " 'C3.E-3': 110,\n",
       " 'C3.F#3': 111,\n",
       " 'C3.F3': 112,\n",
       " 'C4': 113,\n",
       " 'C4.A4': 114,\n",
       " 'C4.B-4': 115,\n",
       " 'C4.C#4': 116,\n",
       " 'C4.C5': 117,\n",
       " 'C4.D4': 118,\n",
       " 'C4.E-4': 119,\n",
       " 'C4.E4': 120,\n",
       " 'C4.F#4': 121,\n",
       " 'C4.F4': 122,\n",
       " 'C4.G4': 123,\n",
       " 'C5': 124,\n",
       " 'C5.C#5': 125,\n",
       " 'C5.D5': 126,\n",
       " 'C5.E-5': 127,\n",
       " 'C5.F5': 128,\n",
       " 'C5.G5': 129,\n",
       " 'C6': 130,\n",
       " 'C6.C#6.D6': 131,\n",
       " 'C6.D6': 132,\n",
       " 'D3': 133,\n",
       " 'D3.A3': 134,\n",
       " 'D3.B4': 135,\n",
       " 'D3.E-3': 136,\n",
       " 'D3.E3': 137,\n",
       " 'D3.F#3': 138,\n",
       " 'D3.F3': 139,\n",
       " 'D3.G3': 140,\n",
       " 'D4': 141,\n",
       " 'D4.A4': 142,\n",
       " 'D4.B-4': 143,\n",
       " 'D4.B4': 144,\n",
       " 'D4.E-4': 145,\n",
       " 'D4.E-4.F4': 146,\n",
       " 'D4.E4': 147,\n",
       " 'D4.E4.F#4': 148,\n",
       " 'D4.F#4': 149,\n",
       " 'D4.F4': 150,\n",
       " 'D4.G#4': 151,\n",
       " 'D4.G4': 152,\n",
       " 'D5': 153,\n",
       " 'D5.E-5': 154,\n",
       " 'D5.E5': 155,\n",
       " 'D5.F#5': 156,\n",
       " 'D5.F5': 157,\n",
       " 'D5.G5': 158,\n",
       " 'D6': 159,\n",
       " 'E-3': 160,\n",
       " 'E-3.A3': 161,\n",
       " 'E-3.B-3': 162,\n",
       " 'E-3.B3': 163,\n",
       " 'E-3.D4': 164,\n",
       " 'E-3.E3': 165,\n",
       " 'E-3.F#3': 166,\n",
       " 'E-3.F3': 167,\n",
       " 'E-3.G#3': 168,\n",
       " 'E-3.G3': 169,\n",
       " 'E-3.G4': 170,\n",
       " 'E-4': 171,\n",
       " 'E-4.A4': 172,\n",
       " 'E-4.B-4': 173,\n",
       " 'E-4.B4': 174,\n",
       " 'E-4.C5': 175,\n",
       " 'E-4.E4': 176,\n",
       " 'E-4.F#4': 177,\n",
       " 'E-4.F4': 178,\n",
       " 'E-4.F4.G4': 179,\n",
       " 'E-4.G#4': 180,\n",
       " 'E-4.G4': 181,\n",
       " 'E-5': 182,\n",
       " 'E-5.B5': 183,\n",
       " 'E-5.E5': 184,\n",
       " 'E-5.F#5': 185,\n",
       " 'E-5.F5': 186,\n",
       " 'E-5.G#5': 187,\n",
       " 'E-5.G5': 188,\n",
       " 'E-6': 189,\n",
       " 'E3': 190,\n",
       " 'E3.A3': 191,\n",
       " 'E3.F#3': 192,\n",
       " 'E3.F3': 193,\n",
       " 'E3.G#3': 194,\n",
       " 'E3.G3': 195,\n",
       " 'E4': 196,\n",
       " 'E4.A4': 197,\n",
       " 'E4.B-4': 198,\n",
       " 'E4.B4': 199,\n",
       " 'E4.C#5': 200,\n",
       " 'E4.C5': 201,\n",
       " 'E4.F#4': 202,\n",
       " 'E4.F#4.G#4.B-4': 203,\n",
       " 'E4.F4': 204,\n",
       " 'E4.G#4': 205,\n",
       " 'E4.G4': 206,\n",
       " 'E5': 207,\n",
       " 'E5.B5': 208,\n",
       " 'E5.F#5': 209,\n",
       " 'E5.F5': 210,\n",
       " 'E5.G5': 211,\n",
       " 'F#3': 212,\n",
       " 'F#3.A3': 213,\n",
       " 'F#3.B-3': 214,\n",
       " 'F#3.B3': 215,\n",
       " 'F#3.C#4': 216,\n",
       " 'F#3.G#3': 217,\n",
       " 'F#3.G3': 218,\n",
       " 'F#4': 219,\n",
       " 'F#4.A4': 220,\n",
       " 'F#4.B-4': 221,\n",
       " 'F#4.B4': 222,\n",
       " 'F#4.C#5': 223,\n",
       " 'F#4.C5': 224,\n",
       " 'F#4.G#4': 225,\n",
       " 'F#4.G4': 226,\n",
       " 'F#4.G4.G#4': 227,\n",
       " 'F#5': 228,\n",
       " 'F#5.A5': 229,\n",
       " 'F#5.B5': 230,\n",
       " 'F#5.G#5': 231,\n",
       " 'F#5.G5': 232,\n",
       " 'F2': 233,\n",
       " 'F3': 234,\n",
       " 'F3.A3': 235,\n",
       " 'F3.B-3': 236,\n",
       " 'F3.B3': 237,\n",
       " 'F3.C4': 238,\n",
       " 'F3.D4': 239,\n",
       " 'F3.E-4': 240,\n",
       " 'F3.F#3': 241,\n",
       " 'F3.G#3': 242,\n",
       " 'F3.G3': 243,\n",
       " 'F4': 244,\n",
       " 'F4.A4': 245,\n",
       " 'F4.B-4': 246,\n",
       " 'F4.B4': 247,\n",
       " 'F4.C5': 248,\n",
       " 'F4.E-5': 249,\n",
       " 'F4.F#4': 250,\n",
       " 'F4.F#4.A4.B-4': 251,\n",
       " 'F4.F#4.G4': 252,\n",
       " 'F4.G#4': 253,\n",
       " 'F4.G4': 254,\n",
       " 'F4.G4.A4': 255,\n",
       " 'F5': 256,\n",
       " 'F5.F#5': 257,\n",
       " 'F5.G5': 258,\n",
       " 'G#2': 259,\n",
       " 'G#2.B-3': 260,\n",
       " 'G#3': 261,\n",
       " 'G#3.A3': 262,\n",
       " 'G#3.B-3': 263,\n",
       " 'G#3.B3': 264,\n",
       " 'G#3.C#4': 265,\n",
       " 'G#3.C4': 266,\n",
       " 'G#3.D4': 267,\n",
       " 'G#3.E-4': 268,\n",
       " 'G#3.G#4': 269,\n",
       " 'G#4': 270,\n",
       " 'G#4.A4': 271,\n",
       " 'G#4.B-4': 272,\n",
       " 'G#4.B4': 273,\n",
       " 'G#4.C#5': 274,\n",
       " 'G#4.C5': 275,\n",
       " 'G#4.D5': 276,\n",
       " 'G#4.F#5': 277,\n",
       " 'G#5': 278,\n",
       " 'G#5.A5': 279,\n",
       " 'G#5.B-5': 280,\n",
       " 'G#5.B5': 281,\n",
       " 'G2': 282,\n",
       " 'G2.E-3': 283,\n",
       " 'G3': 284,\n",
       " 'G3.A3': 285,\n",
       " 'G3.B-3': 286,\n",
       " 'G3.B3': 287,\n",
       " 'G3.C#4': 288,\n",
       " 'G3.C4': 289,\n",
       " 'G3.D4': 290,\n",
       " 'G3.E-4': 291,\n",
       " 'G3.G#3': 292,\n",
       " 'G4': 293,\n",
       " 'G4.A4': 294,\n",
       " 'G4.A4.B4': 295,\n",
       " 'G4.B-4': 296,\n",
       " 'G4.B-4.C5': 297,\n",
       " 'G4.B4': 298,\n",
       " 'G4.C#5': 299,\n",
       " 'G4.C5': 300,\n",
       " 'G4.D5': 301,\n",
       " 'G4.G#4': 302,\n",
       " 'G5': 303,\n",
       " 'G5.A5': 304,\n",
       " 'G5.A5.B5': 305,\n",
       " 'G5.G#5': 306,\n",
       " 'START': 307}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('\\nnote_to_int')\n",
    "note_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "duration_to_int\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " Fraction(1, 12): 1,\n",
       " Fraction(1, 6): 2,\n",
       " 0.25: 3,\n",
       " Fraction(1, 3): 4,\n",
       " Fraction(5, 12): 5,\n",
       " 0.5: 6,\n",
       " Fraction(7, 12): 7,\n",
       " Fraction(2, 3): 8,\n",
       " 0.75: 9,\n",
       " Fraction(5, 6): 10,\n",
       " Fraction(11, 12): 11,\n",
       " 1.0: 12,\n",
       " Fraction(13, 12): 13,\n",
       " Fraction(7, 6): 14,\n",
       " 1.25: 15,\n",
       " Fraction(4, 3): 16,\n",
       " Fraction(17, 12): 17,\n",
       " 1.5: 18,\n",
       " Fraction(19, 12): 19,\n",
       " Fraction(5, 3): 20,\n",
       " 1.75: 21,\n",
       " Fraction(11, 6): 22,\n",
       " Fraction(23, 12): 23,\n",
       " 2.0: 24,\n",
       " Fraction(25, 12): 25,\n",
       " Fraction(13, 6): 26,\n",
       " 2.25: 27,\n",
       " Fraction(7, 3): 28,\n",
       " Fraction(29, 12): 29,\n",
       " 2.5: 30,\n",
       " Fraction(31, 12): 31,\n",
       " Fraction(8, 3): 32,\n",
       " 2.75: 33,\n",
       " Fraction(17, 6): 34,\n",
       " Fraction(35, 12): 35,\n",
       " 3.0: 36,\n",
       " Fraction(19, 6): 37,\n",
       " 3.25: 38,\n",
       " Fraction(10, 3): 39,\n",
       " 3.5: 40,\n",
       " Fraction(43, 12): 41,\n",
       " Fraction(11, 3): 42,\n",
       " 3.75: 43,\n",
       " Fraction(23, 6): 44,\n",
       " 4.0: 45,\n",
       " Fraction(49, 12): 46,\n",
       " 4.25: 47,\n",
       " Fraction(13, 3): 48,\n",
       " Fraction(53, 12): 49,\n",
       " 4.5: 50,\n",
       " Fraction(14, 3): 51,\n",
       " 4.75: 52,\n",
       " 5.0: 53,\n",
       " 5.25: 54,\n",
       " 5.5: 55,\n",
       " 5.75: 56,\n",
       " 6.0: 57,\n",
       " 6.25: 58,\n",
       " Fraction(77, 12): 59,\n",
       " 6.5: 60,\n",
       " Fraction(20, 3): 61,\n",
       " 7.25: 62,\n",
       " Fraction(23, 3): 63,\n",
       " 8.0: 64,\n",
       " Fraction(38, 3): 65,\n",
       " 28.25: 66}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('\\nduration_to_int')\n",
    "duration_to_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the sequences used by the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_input, network_output = prepare_sequences(notes, durations, lookups, distincts, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pitch input\n",
      "[307 196 141 244 244 293  13 293 244 150 141  13 142 141 244  13 294 293\n",
      "  13 294 293 141 244 196 293 302 270  13  13  13  13 293]\n",
      "duration input\n",
      "[ 0 30 12  9  9  8 28  4  6  2 13 14  1  5 36 13  2  2  5  1  5  4 15  3\n",
      "  3  1  2 38 12  8 12  6]\n",
      "pitch output\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "duration output\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print('pitch input')\n",
    "print(network_input[0][0])\n",
    "print('duration input')\n",
    "print(network_input[1][0])\n",
    "print('pitch output')\n",
    "print(network_output[0][0])\n",
    "print('duration output')\n",
    "print(network_output[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the structure of the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Please provide to Input either a `shape` or a `batch_shape` argument. Note that `shape` does not include the batch dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0c7cf4775aa7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matt_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_network_no_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_notes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_durations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_attention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/GDL_code/models/RNNAttention.py\u001b[0m in \u001b[0;36mcreate_network_no_embed\u001b[0;34m(n_notes, n_durations, rnn_units, use_attention, reg, learning_rate)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_network_no_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_notes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_durations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_units\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;34m\"\"\" create the structure of the neural network \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;31m#first layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m#x = LSTM(rnn_units, return_sequences=True, recurrent_dropout = 0.5, kernel_regularizer=reg)(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/input_layer.py\u001b[0m in \u001b[0;36mInput\u001b[0;34m(shape, batch_shape, name, dtype, sparse, tensor)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \"\"\"\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbatch_shape\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         assert shape is not None, ('Please provide to Input either a `shape`'\n\u001b[0m\u001b[1;32m    168\u001b[0m                                    \u001b[0;34m' or a `batch_shape` argument. Note that '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                                    \u001b[0;34m'`shape` does not include the batch '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Please provide to Input either a `shape` or a `batch_shape` argument. Note that `shape` does not include the batch dimension."
     ]
    }
   ],
   "source": [
    "model, att_model = create_network_no_embed(n_notes, n_durations, rnn_units, use_attention, reg, learning_rate)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_model(model, to_file=os.path.join(run_folder ,'viz/model.png'), show_shapes = True, show_layer_names = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_folder = os.path.join(run_folder, 'weights')\n",
    "# model.load_weights(os.path.join(weights_folder, \"weights.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_folder = os.path.join(run_folder, 'weights')\n",
    "\n",
    "checkpoint1 = ModelCheckpoint(\n",
    "    os.path.join(weights_folder, \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.h5\"),\n",
    "    monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "checkpoint2 = ModelCheckpoint(\n",
    "    os.path.join(weights_folder, \"weights.h5\"),\n",
    "    monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='loss'\n",
    "    , restore_best_weights=True\n",
    "    , patience = 10\n",
    ")\n",
    "\n",
    "\n",
    "callbacks_list = [\n",
    "    checkpoint1\n",
    "    , checkpoint2\n",
    "    , early_stopping\n",
    " ]\n",
    "\n",
    "model.save_weights(os.path.join(weights_folder, \"weights.h5\"))\n",
    "history = model.fit(network_input, network_output\n",
    "          , epochs=1000, batch_size=32\n",
    "          , validation_split = 0.2\n",
    "          , callbacks=callbacks_list\n",
    "          , shuffle=True\n",
    "         )\n",
    "\n",
    "train_history = history.history['loss']\n",
    "val_history = history.history['val_loss']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(train_history, color='blue', label='train')\n",
    "pyplot.plot(val_history, color='orange', label='validation')\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='lower left')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
